{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOo2KMLNQpPTbklO0ORJvDF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MitjaGo/YT/blob/main/booking_scrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1Ô∏è‚É£ Install packages (if not done already)\n",
        "!pip install --quiet selenium webdriver-manager beautifulsoup4 lxml pandas tabulate ipywidgets\n",
        "\n",
        "# 2Ô∏è‚É£ Imports\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import datetime\n",
        "import re\n",
        "\n",
        "# 3Ô∏è‚É£ Configure headless Chrome\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
        "\n",
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "# 4Ô∏è‚É£ Currency conversion table (static rates for simplicity)\n",
        "# If symbol unknown, will leave as N/A\n",
        "currency_rates = {\n",
        "    \"‚Ç¨\": 1,       # EUR\n",
        "    \"EUR\": 1,\n",
        "    \"$\": 0.93,    # USD ‚Üí EUR (example)\n",
        "    \"¬£\": 1.13     # GBP ‚Üí EUR (example)\n",
        "}\n",
        "\n",
        "# Function to normalize price string to float in EUR\n",
        "def normalize_price(price_str):\n",
        "    if not price_str or price_str.strip() == \"\":\n",
        "        return \"N/A\"\n",
        "\n",
        "    # Remove non-breaking spaces and common unicode\n",
        "    price_str = price_str.replace(\"\\xa0\", \"\").replace(\",\", \".\").strip()\n",
        "\n",
        "    # Extract currency symbol and numeric part\n",
        "    match = re.search(r\"([‚Ç¨$¬£]|EUR|GBP|USD)?\\s*([\\d\\.]+)\", price_str)\n",
        "    if not match:\n",
        "        return \"N/A\"\n",
        "\n",
        "    symbol, amount = match.groups()\n",
        "    amount = float(amount)\n",
        "    rate = currency_rates.get(symbol, None)\n",
        "\n",
        "    if rate is None:\n",
        "        return \"N/A\"\n",
        "\n",
        "    price_eur = round(amount * rate, 2)\n",
        "    return f\"‚Ç¨{price_eur}\"\n",
        "\n",
        "# 5Ô∏è‚É£ Robust scraper function\n",
        "def get_booking_data(url, checkin, checkout):\n",
        "    # Format dates for Booking.com (YYYY-MM-DD)\n",
        "    checkin_fmt = datetime.datetime.strptime(checkin, \"%d-%m-%Y\").strftime(\"%Y-%m-%d\")\n",
        "    checkout_fmt = datetime.datetime.strptime(checkout, \"%d-%m-%Y\").strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    if \"checkin\" not in url:\n",
        "        joiner = \"&\" if \"?\" in url else \"?\"\n",
        "        url = f\"{url}{joiner}checkin={checkin_fmt}&checkout={checkout_fmt}\"\n",
        "\n",
        "    print(f\"üîó Loading: {url}\")\n",
        "    driver.get(url)\n",
        "\n",
        "    try:\n",
        "        WebDriverWait(driver, 15).until(\n",
        "            EC.presence_of_element_located((By.CSS_SELECTOR, \"[data-testid='room-name']\"))\n",
        "        )\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è Room elements not found. Page may have loaded differently.\")\n",
        "\n",
        "    soup = BeautifulSoup(driver.page_source, \"lxml\")\n",
        "    rooms = []\n",
        "\n",
        "    # Find all room blocks\n",
        "    room_blocks = soup.select(\"[data-testid='room-name']\")\n",
        "    if not room_blocks:\n",
        "        room_blocks = soup.select(\".hprt-roomtype-icon-link\")\n",
        "\n",
        "    if not room_blocks:\n",
        "        rooms.append({\"room\": \"N/A\", \"price\": \"N/A\"})\n",
        "        return rooms\n",
        "\n",
        "    for room in room_blocks:\n",
        "        name = room.get_text(strip=True) if room else \"N/A\"\n",
        "        price_el = room.find_next(\"span\", attrs={\"data-testid\": \"price-and-discounted-price\"})\n",
        "        if not price_el:\n",
        "            price_tag = room.find_next([\"span\", \"div\"], class_=[\"bui-price-display__value\"])\n",
        "            price = normalize_price(price_tag.get_text(strip=True)) if price_tag else \"N/A\"\n",
        "        else:\n",
        "            price = normalize_price(price_el.get_text(strip=True))\n",
        "        rooms.append({\"room\": name, \"price\": price})\n",
        "\n",
        "    return rooms\n",
        "\n",
        "# 6Ô∏è‚É£ Interactive widgets\n",
        "print(\"Enter 3 Booking.com property URLs:\")\n",
        "url_widgets = [widgets.Text(description=f\"URL {i+1}\", placeholder=\"https://\") for i in range(3)]\n",
        "for w in url_widgets:\n",
        "    display(w)\n",
        "\n",
        "# Date pickers for multiple check-in/check-out\n",
        "checkin_widgets = [widgets.DatePicker(description=f\"Check-in {i+1}\") for i in range(2)]\n",
        "checkout_widgets = [widgets.DatePicker(description=f\"Check-out {i+1}\") for i in range(2)]\n",
        "print(\"\\nEnter multiple check-in and check-out dates:\")\n",
        "for ci, co in zip(checkin_widgets, checkout_widgets):\n",
        "    display(ci, co)\n",
        "\n",
        "# Button to start scraping\n",
        "button = widgets.Button(description=\"Scrape Data\", button_style=\"success\")\n",
        "output = widgets.Output()\n",
        "display(button, output)\n",
        "\n",
        "# 7Ô∏è‚É£ Scrape on button click\n",
        "def on_button_clicked(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        # Collect URLs\n",
        "        urls = [w.value.strip() for w in url_widgets if w.value]\n",
        "        if not urls:\n",
        "            print(\"‚ö†Ô∏è Please enter at least one property URL.\")\n",
        "            return\n",
        "\n",
        "        # Collect dates\n",
        "        date_pairs = []\n",
        "        for ci, co in zip(checkin_widgets, checkout_widgets):\n",
        "            if ci.value and co.value:\n",
        "                ci_str = ci.value.strftime(\"%d-%m-%Y\")\n",
        "                co_str = co.value.strftime(\"%d-%m-%Y\")\n",
        "                date_pairs.append((ci_str, co_str))\n",
        "\n",
        "        if not date_pairs:\n",
        "            print(\"‚ö†Ô∏è Please enter at least one check-in/check-out pair.\")\n",
        "            return\n",
        "\n",
        "        # Scrape all combinations\n",
        "        results = []\n",
        "        for i, url in enumerate(urls):\n",
        "            for checkin, checkout in date_pairs:\n",
        "                print(f\"\\nüîç Scraping property {i+1} for {checkin} ‚Üí {checkout}\")\n",
        "                data = get_booking_data(url, checkin, checkout)\n",
        "                for item in data:\n",
        "                    results.append({\n",
        "                        \"Property\": f\"Property {i+1}\",\n",
        "                        \"Room Type\": item.get(\"room\", \"N/A\"),\n",
        "                        \"Price (EUR)\": item.get(\"price\", \"N/A\"),\n",
        "                        \"Check-in\": checkin,\n",
        "                        \"Check-out\": checkout,\n",
        "                        \"URL\": url\n",
        "                    })\n",
        "\n",
        "        driver.quit()\n",
        "\n",
        "        if results:\n",
        "            df = pd.DataFrame(results)\n",
        "            df = df[[\"Property\", \"Room Type\", \"Price (EUR)\", \"Check-in\", \"Check-out\", \"URL\"]]\n",
        "            print(\"\\n‚úÖ Scraping completed!\\n\")\n",
        "            print(tabulate(df, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è No data found. Try increasing wait time or check your URLs.\")\n",
        "\n",
        "button.on_click(on_button_clicked)\n"
      ],
      "metadata": {
        "id": "eu5tI9u3P0Si"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}